## C02w05: Feature Selection and Lasso

[Machine Learning(ML) Specialization](https://www.coursera.org/specializations/machine-learning)
  - [ML Regression Course](https://www.coursera.org/learn/ml-regression/home/welcome)

### Using LASSO to select features
In this assignment, we will use LASSO to select features, building on a pre-implemented solver for LASSO (using Turi Create, though you can use other solvers).
We will:
  - Write a function to normalize features
  - Implement coordinate descent for LASSO
  - Explore effects of L1 penalty


### Implementing LASSO using coordinate descent
In this notebook, we will implement our very own LASSO solver via coordinate descent.
We will:
  - Write a function to normalize features
  - Implement coordinate descent for LASSO
  - Explore effects of L1 penalty

<hr />

Addition;
  - Complete port to [Julia](https://www.julialang.org/)

Outcome:
  - [Jupyter Notebook/PA1](https://github.com/pascal-p/ML_UW_Spec/blob/main/C02/w05/C02w05_nb_pa1.ipynb)
  - [Jupyter Notebook/PA2](https://github.com/pascal-p/ML_UW_Spec/blob/main/C02/w05/C02w05_nb_pa2.ipynb)
  - [Julia Notebook/PA2](https://github.com/pascal-p/ML_UW_Spec/blob/main/C02/w05/C02w05_nb_pa2.jl)

<hr />
<p><sub><em>Feb. 2021 Corto Inc</sub></em></p>
